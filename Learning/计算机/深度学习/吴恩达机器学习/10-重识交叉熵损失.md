>[一文搞懂交叉熵在机器学习中的使用，透彻理解交叉熵背后的直觉-CSDN博客](https://blog.csdn.net/tsyccnh/article/details/79163834)

- 要弄清楚，什么是多分类，比如一张图片，它有两个动物，它就不只属于一个类别
- 越不确定，熵就越大

P往往用来表示样本的真实分布，比如$[1,0,0]$表示当前样本属于第一类。Q用来表示模型所预测的分布，比如$[0.7,0.2,0.1]$
$$D_{KL}(p||q) = \sum_{i=1}^n p(x_i)log(\frac{p(x_i)}{q(x_i)})$$
**n为事件的所有可能性**, 是一个样本的可能性，而不是多个样本
$D_{KL}$ 的值越小，表示q分布和p分布越接近