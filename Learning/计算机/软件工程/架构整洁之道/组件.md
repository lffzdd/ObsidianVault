---
aliases: 组件
date created: Monday, April 28th 2025, 3:18:06 pm
date modified: Monday, April 28th 2025, 3:54:14 pm
---
在早期的软件开发中，程序员可以完全掌控自己编写的程序所处的内存地址和存放格式。在那时，程序中的第一条语句被称为起源 （origin）语句，它的作用是声明该程序应该被加载到的内存位置。
当时的程序基本不能被重定位,那么，当时是如何调用库函数呢？程序员们需要将所有要调用的库函数源代码包含到自己的程序代码中，然后再进行整体编译。库函数文件都是以源代码而非二进制的形式保存的。这样做的好处是可以避免在调用库函数时出现不必要的内存地址冲突，但缺点是会使得程序的体积变得很大。
在那个年代，存储设备十分缓慢，而内存则非常昂贵，也非常有限。编译器在编译程序的过程中需要数次遍历整个源代码。由于内存非常有限，驻留所有的源代码是不现实的，编译器只能多次从缓慢的存储设备中读取源代码。这样做是十分耗时的——库函数越多，编译就越慢。大型程序的编译过程经常需要几个小时。
为了缩短编译时间，程序员们改将库函数的源代码单独编译。而库函数的源代码在单独编译后会被加载到一个指定位置，比如地址 2000（八进制）。然后，编译器会针对该库文件创建一个符号表 （symbol table），并将其和应用程序代码编译在一起。当程序运行时，它会先加载二进制形式的库文件，再加载编译过的应用程序，其内存布局如图 12.1 所示。![[Pasted image 20250428152816.png]]
当然，只要应用程序的代码能够完全存放在地址 0000～1777（八进制）内，这种组织方式就没有任何问题。但是，应用程序代码的大小很快就会超出这个范围。为了解决这个问题，程序员们必须将应用程序代码切分成两个不同的地址段，以跳过库函数存放的内存范围 ![[Pasted image 20250428153043.png]]
很显然，这种方案也是不可持续的。因为随着函数库中函数的增加，它的大小也随之增加，我们同样也需要为此划分新的区域，譬如在上述例子中，我们需要在 7000（八进制）左右的位置往后追加地址空间。这样一来，程序和函数库的碎片化程度会随着计算机内存的增加而不断增加。显而易见，这个问题必须要有一个解决方案。

**重定位技术**
该解决方案就是生成可==重定位==的二进制文件。
其背后的原理非常简单，即程序员修改编译器输出文件的二进制格式，使其可以由一个智能加载器加载到任意内存位置。
当然，这需要我们在加载器启动时为这些文件指定要加载到的内存地址，而且可重定位的代码中还包含了一些记号，加载器将其加载到指定位置时会修改这些记号对应的地址值。==一般来说，这个过程只不过就是将二进制文件中包含的内存地址都按照其加载到的内存基础位置进行递增。==
这样一来，程序员们就可以用加载器来调整函数库及应用程序的位置了。事实上，这种加载器还可以接受多个二进制文件的输入，并按顺序在内存中加载它们，再逐个进行重定位。这样，==程序员们就可以只加载他们实际会用到的函数了。==

- ~ 除此之外，程序员们还对编译器做了另外一个修改，就是在可重定位二进制文件中将函数名输出为元数据并存储起来。这样一来，如果一段程序调用了某个库函数，编译器就会将这个函数的名字输出为外部引用（external reference），而将库函数的定义输出为外部定义（external definition）。加载器在加载完程序后，会将外部引用和外部定义链接（link）起来。这就是链接加载器（linking loader）的由来。

**链接器**
链接加载器让程序员们可以将程序切分成多个可被分别编译、加载的程序段。在程序规模较小、外部链接也较少的情况下，这个方案一直都很好用。然而在 20 世纪 60 年代末期到 70 年代初期的那段时间里，程序的规模突然有了大幅的增长，情况就有所不同了。
在这种情况下，链接加载器的处理过程太慢。函数库当时还存储在磁带卷这样的低速存储设备上，即使是存储在磁盘上，其存取速度也是很慢的。链接加载器在加载处理过程中必须要读取几十个甚至几百个二进制库文件来解析外部引用。因此随着程序规模的扩大，以及函数库中函数的累积，链接加载器的**加载**过程经常会出现需要一个多小时才能完成的情况。
最后，程序员们只能将加载过程和链接过程也进行分离。他们将耗时较长的部分——链接部分——放到了一个单独的程序中去进行，这个程序就是所谓的**链接器（linker）**。==链接器的输出是一个已经完成了外部链接的、可以重定位的二进制文件==，这种文件可以由一个支持重定位的加载器迅速加载到内存中。这使得程序员可以用缓慢的链接器生产出可以很快进行多次加载的可执行文件

时间继续推移到了 20 世纪 80 年代，程序员们在那时已经用上了 C 这样的高级编程语言，程序的规模也得到了进一步的扩大，源代码行数超过几十万行在当时已经是很普遍的事了。于是，源代码模块会从．c 文件被编译成．o 文件，然后再由链接器创建出可被快速加载的可执行文件。那时，虽然编译每个单独模块的速度相对较快，但所有模块的累计编译时间较长，链接过程则耗时更久，整个修改编译周期经常会超过数个小时
有时候，程序员们看上去似乎就是一直不停地在原地打转。从 20 世纪 60 年代一直到 80 年代，他们所有为提供编译速度所做的努力都被不断增长的程序规模抵消了。程序员好像永远也脱离不了长达几个小时的修改编译周期。程序加载的速度一直都很快，但是其编译和链接的过程也一直是整个开发过程的瓶颈。这被我们称为程序规模上的墨菲定律：
> 程序的规模会一直不断地增长下去，直到将有限的编译和链接时间填满为止。

除了墨菲定律，我们还有摩尔定律。在 20 世纪 80 年代，两个定律一直在互相较量，最终以摩尔定律获胜告终。因为磁盘的物理尺寸一直在不断缩小，速度在不断提高，同时内存的造价也一直在不断降低，以至于大部分存放在磁盘上的数据都可以被缓存在内存中了。而计算机时钟频率则从 1MHz 上升到了 100MHz。
到了 20 世纪 90 年代中期，==链接速度的提升速度已经远远超过了程序规模的增长速度==。在大部分情况下，程序链接的时间已经降低到秒级。这对一些小程序来说，即使使用链接加载器也是可以接受的了。
与此同时，编程领域中还诞生了 Active-X、共享库、.jar 文件等组件形式。==由于计算与存储速度的大幅提高，我们又可以在加载过程中进行实时链接了==，链接几个．jar 文件或是共享库文件通常只需要几秒钟时间，由此，插件化架构也就随之诞生了。
如今，我们用.jar 文件、DLL 文件和共享库方式来部署应用的插件已经非常司空见惯了。如果现在我们想要给 Minecraft 增加一个模块，只需要将.jar 文件放到一个指定的目录中即可。同样的，如果你想给 Visual Studio 增加 Resharper 插件，也只需要安装对应的 DLL 文件即可

我们常常会在程序运行时插入某些动态链接文件，这些动态链接 文件所使用的就是软件架构中的组件概念。在经历了50年的演进之后，组件化的插件式架构已经成为我们习以为常的软件构建形式了。