---
aliases: IO模型
tags: []
date created: 星期四, 四月 3日 2025, 12:43:12 下午
date modified: 星期四, 四月 3日 2025, 5:36:39 下午
---
# 五种 IO 模型
1. blockingIO - 阻塞 IO
2. nonblockingIO - 非阻塞 IO
3. signaldrivenIO - 信号驱动 IO
4. asynchronousIO - 异步 IO
5. IOmultiplexing - IO 多路复用
# 非阻塞 I\/O 和信号驱动 I\/O
你的理解已经很深入了，基本抓住了两者的核心区别！你的疑惑点也很关键，特别是你发现了**非阻塞 I\/O 和信号驱动 I\/O 都涉及 " 信号 " 机制**，但它们的工作方式不同。我们可以更细致地分析它们的区别，来解答你的疑问。
### **1. 非阻塞 I\/O（Non-blocking I\/O）**
> **特点**：进程主动多次调用 `read()` / `recv()`，如果数据还没准备好，内核立即返回 `EAGAIN` 或 `EWOULDBLOCK`，进程需要不断轮询。
#### **具体流程**
1. 进程调用 `read()` / `recv()` 读取数据；
2. **如果数据已经准备好（在内核缓冲区）**，则内核直接返回数据；
3. **如果数据还没准备好**：
    - 进程不会被挂起，而是立即返回 `EAGAIN`（表示资源暂时不可用）；
    - 进程继续执行自己的任务，稍后再尝试读取；
4. 进程必须不断地重复调用 `read()` / `recv()`，直到数据可用。
#### **关键点**
- 进程**主动轮询**，消耗 CPU，可能会有大量无效调用；
- 适用于短时间内数据就绪的情况；
- 轮询机制本身效率不高，容易浪费 CPU 资源。
---
### **2. 信号驱动 I\/O（Signal-driven I\/O）**
> **特点**：进程在发起 `read()` 之前，先注册一个**信号处理函数**，当数据准备好时，内核**主动**发送 `SIGIO` 信号给进程，进程在信号处理函数中读取数据。
#### **具体流程**
1. 进程调用 `fcntl(fd, F_SETFL, O_ASYNC)` 设置 **异步 I\/O**；
2. 进程使用 `fcntl(fd, F_SETOWN, getpid())` 设置**信号接收者**（当前进程）；
3. 进程注册 `SIGIO` 处理函数，并返回，不会被阻塞；
4. 当数据准备好时，内核**自动**发送 `SIGIO` 信号给进程；
5. 进程的 `SIGIO` 处理函数被触发，调用 `read()` 读取数据。
#### **关键点**
- 进程**不主动轮询**，而是被动等待 `SIGIO` 信号；
- 适用于高并发场景，避免了无效的 `read()` 调用，效率更高；
- 但信号的处理开销可能比 `epoll` 更大，因此在高性能应用中 `epoll` 更常用。
---
### **3. 你的核心疑问解析**
#### **(1) 为什么说非阻塞 I\/O 也涉及 " 信号 "？**
你的思路是对的，**在底层，所有 I\/O 设备完成操作时，都会触发中断（Interrupt），然后内核处理**。但这里的 " 信号 " 概念不同：
- **非阻塞 I\/O 只是不等数据就绪直接返回，进程必须不断轮询。**
- **信号驱动 I\/O 是由内核在数据就绪时主动通知进程（发送 `SIGIO` 信号），进程不需要轮询。**
所以，虽然底层 I\/O 设备确实是依赖中断通知内核的，但在进程层面，" 信号驱动 I\/O" 这个术语是专门指进程通过 `SIGIO` 机制被动接收通知，而不是主动轮询。
---
#### **(2) 为什么非阻塞 I\/O 需要多次轮询，而信号驱动 I\/O 不需要？**
你提到的：
> **非阻塞式一直傻傻地问不太合理，会发起多次无效调用，而信号驱动就没有无效调用，效率应当更高才是。**
这确实是信号驱动 I\/O 设计的一个优势。**非阻塞 I\/O 需要进程主动轮询**，这意味着：
- 进程每次 `read()` 都会触发一次系统调用，即使数据没准备好，仍然会有上下文切换的开销；
- 如果数据一直未准备好，进程会反复执行无效的 `read()`，浪费 CPU 资源。
而**信号驱动 I\/O 由内核在数据准备好时主动通知进程**：
- 进程只需要在 `SIGIO` 触发时执行 `read()`，不需要浪费 CPU 轮询；
- 但信号处理有一定的开销，比如信号处理函数的注册和执行，可能会影响实时性。
所以，**信号驱动 I\/O 在减少 CPU 轮询方面确实更高效**，但它仍然有信号调度的开销，因此在超高并发场景下，`epoll` 等 I\/O 多路复用技术更流行。
### **4. 什么时候用非阻塞 I\/O，什么时候用信号驱动 I\/O？**
|I\/O 模型|适用场景|优缺点|
|---|---|---|
|**非阻塞 I\/O**|适用于**短时间内数据就绪**的情况，例如低并发网络服务|简单但可能会浪费 CPU|
|**信号驱动 I\/O**|适用于**需要高效事件驱动**的应用，例如高并发网络服务器|避免无效轮询，但信号处理有额外开销|
### **总结**
1. **非阻塞 I\/O**：
    - 进程主动 `read()`，如果数据未就绪就返回 `EAGAIN`，需要反复轮询；
    - 轮询可能会浪费 CPU，但实现较简单。
2. **信号驱动 I\/O**：
    - 进程注册 `SIGIO` 处理函数，等数据就绪时，内核主动通知；
    - 避免了无效 `read()`，但信号处理有一定开销。
3. **你的理解是对的，信号驱动 I\/O 确实比非阻塞 I\/O 更高效**，因为它避免了不必要的轮询，但**信号处理的开销可能在高并发下成为瓶颈**，所以现代高并发服务器通常用 `epoll` 而不是 `SIGIO`。
---
# 信号驱动 I\/O 和异步 I\/O
你的疑问非常有深度，尤其是关于 **信号驱动 I\/O** 和 **异步 I\/O** 之间的区别。这两者的底层原理确实有相似之处，但关键的不同点在于 **" 谁来负责读取数据 "**。我们来详细拆解一下异步 I\/O (AIO) 的工作方式，并和信号驱动 I\/O (SIGIO) 进行对比，以解答你的疑问。
## **1. 你对异步 I\/O (AIO) 的困惑**
你的问题核心在于：
1. **AIO 进程发起 I\/O 后，什么时候收到通知？**
2. **AIO 是如何通知进程数据已经准备好？它是否也依赖信号？**
3. **AIO 和信号驱动 I\/O 的区别是什么？**
你的猜测部分是正确的，异步 I\/O 的确不能避免设备完成 I\/O 操作的信号（如中断），但它的关键在于 **进程不需要自己调用 `read()` 取数据，而是等内核** **完全处理完** **后，再通知进程**，这和信号驱动 I\/O 存在本质上的不同。
## **2. I\/O 处理的核心阶段**
一个 I\/O 操作（比如 `read()`）主要包含两个阶段：
1. **数据准备阶段（数据从设备到达内核缓冲区）**
    - 可能需要等待设备（如磁盘、网络）完成数据传输
    - 可能会触发中断通知内核数据到达
2. **数据复制阶段（数据从内核缓冲区拷贝到用户空间）**
    - 进程调用 `read()` 之后，内核将数据从内核态拷贝到用户态
不同的 I\/O 模型处理这两个阶段的方式不同：
- **阻塞 I\/O**：两个阶段都阻塞进程
- **非阻塞 I\/O**：两个阶段都不阻塞，但需要主动轮询
- **I\/O 多路复用**：等待多个 `fd` 就绪，但进程最终还是要自己 `read()`
- **信号驱动 I\/O**：数据准备完成后，内核发送 `SIGIO`，但进程**仍需调用 `read()`**
- **异步 I\/O**：**进程发起 I\/O 调用后就完全不管了，内核负责完成整个流程**，数据准备 + 复制都由内核完成，完成后才通知进程。
---
## **3. 异步 I\/O (AIO) 的真正工作方式**
> **核心区别：进程调用 AIO 时，整个 I\/O 过程完全由内核负责，数据准备和数据复制都由内核完成，进程只在最后收到通知**。
### **AIO 具体流程**
1. 进程调用 `aio_read()` 或 `io_submit()` 之类的 AIO 接口，**只告诉内核 " 我要读取数据 "**，但不关心何时完成；
2. 内核返回，进程可以继续做其他事情（不会阻塞等待）；
3. **内核完成整个 I\/O 操作，包括**
    - 等待设备数据就绪
    - 把数据从设备读取到内核缓冲区
    - **把数据从内核缓冲区拷贝到用户缓冲区**
4. 内核完成 I\/O 后，通过 **信号**（如 `SIGEV_SIGNAL`）或**回调函数**通知进程；
5. 进程直接访问数据，而不需要自己 `read()`。
### **4. 信号驱动 I\/O vs. 异步 I\/O**
| |**信号驱动 I\/O** (`SIGIO`)|**异步 I\/O** (`AIO`)|
|---|---|---|
|**进程发起 I\/O 调用**|调用 `read()`，若数据未准备好，则注册 `SIGIO` 信号|调用 `aio_read()` 或 `io_submit()`，告诉内核操作并立即返回|
|**数据准备完成后**|**内核发送 `SIGIO` 信号通知进程**，进程进入信号处理函数|**内核自动完成数据传输**，并通知进程|
|**进程是否需要 `read()` 取数据？**|**需要**，进程仍需手动调用 `read()` 取数据|**不需要**，数据已经放入用户缓冲区|
|**进程是否参与 I\/O 过程？**|**部分参与**，进程只是在数据就绪后自己 `read()`|**完全不参与**，进程等结果即可|
|**是否会有无效调用？**|**不会轮询**，但仍需 `read()` |**不会轮询，也不需 `read()`**|
|**适用于**|网络编程，事件驱动模型（但 `epoll` 更流行）|高性能存储 I\/O，如 `io_uring`|
### **5. AIO 的通知方式**
> 你的疑问： **"AIO 不也是要用信号通知进程数据准备好了？那和信号驱动 I\/O 不是差不多？"**
确实，**AIO 需要某种机制通知进程 I\/O 完成**，但 **AIO 通知进程时，I\/O 已经完全完成了，数据已经到用户空间**，而 `SIGIO` 只是通知进程 " 可以 `read()` 了 "。
在 Linux 下，AIO 通知进程的方法有：
1. **信号（SIGEV_SIGNAL）**
    - 进程注册一个 `SIGEV_SIGNAL`，I\/O 完成后，内核会发送 `SIGIO` 或者其他指定信号。
    - 进程在信号处理函数里获取数据。
2. **回调（SIGEV_THREAD）**
    - 进程注册一个回调函数 (`SIGEV_THREAD`)，I\/O 完成后，内核在独立线程执行回调函数。
    - 这种方式不依赖信号，适合多线程应用。
3. **内核轮询（io_getevents()）**
    - 进程可以调用 `io_getevents()` 轮询完成事件（类似 `epoll`）。
在高性能场景下，现代 Linux 采用 `io_uring`（异步 I\/O 的新实现），它**完全避免了信号**，使用高效的环形缓冲区通信。
## **6. 你的问题最终解答**
> **"AIO 不是也得用信号通知进程？那和信号驱动 I\/O 不是差不多？"**
**区别在于：" 信号驱动 I\/O 只是告诉进程数据到了，但进程还要 `read()`，而 AIO 让内核连 `read()` 也帮你做了 "。**
- **信号驱动 I\/O (`SIGIO`)**：
    - 内核通知进程 " 数据已经准备好 "；
    - 进程还是要 `read()` 取数据。
- **异步 I\/O (`AIO`)**：
    - 内核通知进程 "I\/O 已完成，数据已在你申请的缓冲区里 "；
    - 进程不需要 `read()`，直接用数据。
所以，**信号驱动 I\/O 只是 " 半异步 "，而 AIO 是 " 全异步 "**。
---
## **7. 现代异步 I\/O 的发展**
Linux 传统的 `aio_read()` 在 I\/O 密集场景下仍然有内核上下文切换的开销，所以近年来 `io_uring` 取代了传统 AIO，成为 Linux 5.x 以后的主流异步 I\/O 机制，主要特点：
- **避免了信号和 `read()` 调用**
- **利用内核环形缓冲区，高效通信**
- **适用于 NVMe 存储和高性能网络**
---
## **8. 结论**
✅ **信号驱动 I\/O (`SIGIO`) 和异步 I\/O (`AIO`) 最大的区别是：**
- **信号驱动 I\/O 需要进程 `read()` 取数据**
- **AIO 直接由内核完成 `read()`，数据已经放在用户缓冲区**
所以 **AIO 并不是简单的 " 加了信号的信号驱动 I\/O"，它真正让 I\/O 变成了 " 交给内核全自动处理 "**。
# 信号驱动和异步 I\/O 2
你的疑问很有道理，**信号驱动 I\/O 只是少了一次 `read()`，为什么 AIO 这么重要？** 这个问题涉及到 **系统开销、CPU 并行度、I\/O 阻塞问题**，我们可以从几个角度来分析。
## 1. 进程 `read()` 真的只是一次调用吗？
在信号驱动 I\/O (SIGIO) 中，**少了一次 `read()` 并不仅仅是 " 少一次函数调用 "**，它带来了几个关键的性能影响：
### (1) 进程的 `read()` 可能会发生上下文切换
- **信号驱动 I\/O**：进程收到 `SIGIO` 信号后，需要调用 `read()`，但如果 `read()` 发现数据还未完全到位（因为 I\/O 设备的数据可能是分批次到来的），进程可能会 **再一次被阻塞** 或 **忙等**。
- **异步 I\/O (AIO)**：进程根本不需要关心 `read()`，数据已经准备好，避免了不必要的系统调用和上下文切换。
➡ **减少一次 `read()` 可能意味着减少一次进程阻塞或上下文切换。**
### (2) `read()` 可能会造成额外的 CPU 竞争
- 当进程收到 `SIGIO` 信号后，它必须立即调用 `read()`，但在高并发情况下，这可能导致多个进程/线程同时争抢 CPU，导致 CPU 负载增加，降低系统吞吐量。
- AIO 避免了这种竞争，因为内核在适当的时机把数据直接送到进程的用户缓冲区，进程在接收到通知时数据已经就绪，可以直接使用。
➡ **避免 `read()` 调用，也是在减少 CPU 开销，提高并发能力。**
### (3) `read()` 需要用户态 - 内核态切换
- 进程调用 `read()` 需要进行 **用户态 -> 内核态 -> 用户态** 三次切换，而这次切换是昂贵的：
    - 用户态调用 `read()`
    - 进入内核态，内核检查 I\/O 状态
    - 读取数据到用户缓冲区
    - 切换回用户态
- AIO 直接 **由内核完成 `read()`，避免了额外的系统调用**。
➡ **少一次 `read()`，就少一次用户态 - 内核态切换，系统调用开销也减少了。**
---
## 2. 让 CPU 计算与 I\/O 处理真正并行
信号驱动 I\/O (SIGIO) 依然是 **" 半异步 "**，原因是：
- 进程仍然需要等待 `SIGIO`，然后再 `read()` 获取数据。
- `read()` 仍然需要 CPU 处理，不是完全交给内核。
而 **AIO 是真正的 " 全异步 "**：
- **进程发起 AIO 后，完全可以去做别的事情**（如计算任务）。
- **内核全程负责数据读取，进程不会因为 I\/O 而被迫调度**。
- **进程在数据完全就绪后才被通知，减少了 CPU 介入 I\/O 的时间**。
➡ **AIO 让 CPU 计算与 I\/O 处理可以完全并行，提高吞吐量。**
## **3. AIO 在大规模 I\/O 操作中的优势**
当 I\/O 任务规模变大时（如 10 万个并发请求），**AIO 比 SIGIO 具有显著的性能提升**：
- **信号驱动 I\/O（SIGIO）** 需要在 10 万个请求中，每个请求都触发一个 `SIGIO` 信号，然后进程 `read()`，CPU 会产生大量的 **信号处理开销 + `read()` 调用**，导致 CPU 负载过高。
- **AIO（`io_uring` 等现代实现）** 让内核直接批量处理 I\/O 请求，把数据拷贝到用户缓冲区后，一次性通知进程，减少了 **系统调用 + CPU 负担**。
➡ **在高并发 I\/O 场景下，AIO 的吞吐量远远高于 SIGIO。**
## **4. 现代异步 I\/O (`io_uring`) 的改进**
Linux 传统 AIO (`aio_read()`) 存在一些限制（如依赖 POSIX API，性能较差），但 **现代的 `io_uring`** 彻底改变了 AIO 机制：
- **零拷贝**：数据直接映射到用户空间，减少拷贝次数。
- **批量提交**：可以一次性提交多个 I\/O 请求，提高效率。
- **无信号通知**：不再依赖 `SIGIO`，而是用环形缓冲区高效通知。
➡ **`io_uring` 让 AIO 在现代 Linux 系统中成为最优解，几乎取代了所有传统 I\/O 方式。**
## **5. 结论**
✅ **虽然 AIO 只是 " 少了一次 `read()`"，但它的影响远远不止于此：**
1. **减少系统调用**（避免 `read()` 和用户态 - 内核态切换）。
2. **避免进程阻塞，提高 CPU 并行度**（CPU 计算与 I\/O 处理完全并行）。
3. **减少信号处理开销，提高系统吞吐量**（高并发场景下尤为明显）。
4. **在现代 `io_uring` 中更是彻底避免了信号，进一步优化性能**。
### **总结**
🚀 **信号驱动 I\/O 让 I\/O 变得 " 非阻塞 "，但 AIO 让 I\/O 变得 " 真正异步 "。**
➡ **AIO 让进程可以完全不用关心 I\/O 过程，提高 CPU 并行度，适用于高性能场景。**