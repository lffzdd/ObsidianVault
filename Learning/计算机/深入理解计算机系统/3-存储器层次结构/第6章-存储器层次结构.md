---
aliases: 第6章-存储器层次结构
tags: []
date created: Thursday, January 16th 2025, 7:14:35 pm
date modified: Thursday, January 16th 2025, 9:20:22 pm
---
> [YouTube](https://www.youtube.com/watch?v=FDBqMES--TY&list=PL22J-I2Pi-Gf0s1CGDVtt4vuvlyjLxfem&index=11&ab_channel=RobbieZhou)
## `RAM`
`RAM` 一般分为两种: `SRAM` 和 `DRAM`
`DRAM` 只需要一个晶体管去存储一比特, 而 `SRAM` 更复杂,需要约 4 或 6 个晶体管, 所以 `SRAM` 的成本会高得多
![[Pasted image 20250116191917.png]]
## 磁盘
### 结构
现在说说磁盘结构:
- **Track**: 每一个磁盘有多个同心圆, 每个同心圆都是一个磁道 (track)
- **Sector**: 每个磁道有多个扇区 ![[Pasted image 20250116194317.png]]
- **记录区**: 在以前, 一个磁面的磁道比较少,每个磁道的扇区数是一样的, 越外面的磁道扇区间隙越大.到现在, 磁道密度变大, 为了不让扇区浪费太严重, 划分出了记录区, 每个记录区的扇区数是一样的, 但是外面磁道的扇区会比里面多 ![[Pasted image 20250116194550.png]]
- 磁柱 (cylinder): 多个磁盘上下叠在一起时,同心圆磁道组成了一个柱体
### 磁盘读取
磁盘 span around counter clockwise
![[Pasted image 20250116194850.png]]
一般的硬盘里面含多个磁盘, 读取形式如下 ![[Pasted image 20250116194927.png]]
#### **读**:
![[Pasted image 20250116195327.png]]
如果 cpu 要去读红色的部分, 控制器需要操控读/写头,先将其移回红色扇区所在的磁道, 然后等待磁盘旋转: ![[Pasted image 20250116195555.png]]
### 耗时
所以这里一共有三个因素,决定着阅读其中一个扇区需要多长时间:
- **寻道时间 (seek time):** 移动磁头的时间称为寻道时间
- **旋转延迟 (rotation latency):** 我们等待磁盘旋转，等红色扇区旋转到读写头下方,这部分称为旋转延迟，它通常的平均耗时为磁盘旋转一整圈所花费的时间的一半
- **传送时间 (transfer time):** 最后一个因素是传送时间，是指该轨道在读/写头下通过的时间
为什么要知道这些呢? 这三个因素加在一起, 就是平均值, 即磁盘访问数据需要的平均时间 ![[Pasted image 20250116200147.png]]
寻道时间需要磁头的机械运动, 几十年来都是这个时间, 很难降低
有一个好的经验法则，用于估计从磁盘读取数据所需的时间: 就是两倍的寻道时间
![[Pasted image 20250116200616.png]]
访问 SRAM 取得一个 double 类型的双字，时间大约为 4 纳秒,在 DRAM 上大约是 60 纳秒
但是磁盘比 SRAM 慢 40000 倍
我们用的是扇区, 磁道等几何描述,实际上现代磁盘控制器是将磁盘作为一系列逻辑块提供给 CPU,每个块是扇区大小的整数倍,块从零开始编号.
磁盘控制器保持物理扇区和逻辑块之间的映射,它允许磁盘控制器将一些柱面保留为备用柱面,这些柱面 (cylinder) 没有被映射为逻辑块. 如果有个柱面坏了,磁盘控制器可以将数据复制到备用柱面，然后磁盘就可以继续正常工作.这就是为什么磁盘的 " 格式容量 " 会比实际容量要小，因为其中一些柱面是为故障处理而预留的
## I/O Bus
![[Pasted image 20250116201818.png]]
这是 PCI 结构, 所有的设备都可以看到总线上的数据, 现在的结构是点对点的, 不再是一起的. 总线的每一根线传输一个比特
有一些设备是直接焊接在主板上的，直接连接到总线上: 磁盘是直接插入主板上的插槽,还有诸如图形适配器和 USB 控制器, 系统提供一个接口,因此你可以将鼠标和键盘等插入 USB 控制器
然后还要拓展插槽, 允许你添加其他设备，将其连接到总线上, 例如网络适配器等
当我们想要读取磁盘扇区时会发生什么?
CPU 通过编写三元组来启动此读取行为, 即三个不同的值, 类似于: read 指令 + 逻辑块号 + 内存地址
磁盘控制器 (Disk controller) 读取与该逻辑块对应的所有扇区,然后它做了个有趣的事 -- 它取得总线的控制权, 复制数据,通过 I/O 桥将数据复制到 I/O 总线，直接复制到主存储器，而无需通知 CPU,所以 CPU 完全忘记了这个传输正在进行的事实 ![[Pasted image 20250116202526.png]]
然后,一旦它将数据传输到主存储器,然后它使用这种称为中断的机制来通知 CPU,实际上 CPU 芯片本身上用了一个引脚,它将该引脚的值从 0 更改为 1, 然后 CPU 知道某个程序正在等待数据, CPU 执行该程序并处理该内存中的数据 ![[Pasted image 20250116202813.png]]
那么这个机制有什么好处？他们这样做的原因是因为从磁盘读取数据实在是太慢了,在 10 毫秒内，CPU 可以执行数百万条指令,如果要让 CPU 停下来等待从磁盘上读取数据完毕，那将是一个可怕的浪费. 所以 CPU 将这个事情丢给磁盘控制器
## 固态硬盘
![[Pasted image 20250116203655.png]]
固态硬盘介于旋转磁盘于 DRAM 存储器的中间, 在 CPU 看来,它看起来与旋转磁盘完全相同，它具有相同的接口, 相同的包装, 但固态硬盘没有所有这些机械部件,而是完全由闪存 (flash memory) 构建, 以及充当控制器的固件
因此在固态磁盘内部有一组固件，称为闪存翻译层,其作用与旋转磁盘的磁盘控制器相同, 可以以页为单位从闪存读取和写入数据,页的大小取决于技术的不同，可以是 512 千字节到 4 千字节, 一系列页形成一个 block.这里提到的 block 与 CPU 所认为的逻辑块 (logical block) 是不同的,所以这是一个不幸的术语重叠。
数据是以页为单位写入的, 一个页只能在所属的整个块都被擦除之后，才能写这一页,这似乎有点奇怪，但这就是它的工作方式,那么这意味着你想要对固态硬盘进行写入,如果你想写一个页,**你必须找到一个被擦除的块,你必须将目标块中的所有其他页面复制到该新块,才能正确执行**.好的，你可以看到现在写操作变得相当复杂。读操作没改变，你还是可以读任何东西
然后像所有闪存一样,这是一种有效的机制,因为你正在写一页, 你就必须复制该块中的其他所有页面，你必须擦除整体,然后当你完成后，你擦除这个块以便它可以用于其他写入.
所以最终在经过十万次重复写入后，这个块就会磨损.现代系统的闪存翻译层,实现了各种花里胡哨的专有算法以延长 SSD 的使用生命, 例如缓存技术
下载说说 SSD 的性能, 一个典型的硬盘读写速度可能是每秒 40 或 50MB，这是一个典型的速度,而 SSD 的速度要快 10 倍 ![[Pasted image 20250116205100.png]]
在内存系统中，按顺序执行操作几乎总是比在内存中跳来跳去更好,随机写入速度较慢，是因为擦除的存在，擦除需要大约一毫秒的时间,正如之前所提到的那样，如果你修改某一页，该页所在块中的所有其他页都必须被复制.早期的 SSD 在随机写入和顺序读取的速度存在巨大差距,但因为闪存翻译层的改进，这一差距有所缩小
因为 SSD 没有机械运动部件,所以它们的读写速度非常快，消耗的电能也少，同时也更结实
## The CPU-Memory Gap
![[Pasted image 20250116205527.png]]
你所看到的是一个 CPU 周期的时间从 1985 年到 2003 年以这种指数速度在下降,基本上每 18 个月或两年、时钟频率就会加倍
所以这就是制造商在 2003 年之前所做的事情,为了使他们的处理器更快，他们只会使时钟频率加倍,它们减小了它们制造的芯片的特征尺寸,这可以让制造商把更多的部件放的更紧密,然后按比例增加时钟频率
这一切都在 2003 年结束，这是计算机历史上有趣的一年,因为有一种不幸的特征,就是 CPU 消耗的电能与时钟频率成正比,到 2003 年，英特尔准备新出品的处理器将耗费大约 800 瓦的功率,所以这就是我们所说的处理器设计在 2003 年触及了能源的瓶颈,他们再也不能继续增加时钟频率. 2003 年之后, 他们在芯片上放置了更多处理器内核,所以现在他们将 CPU 芯片细分为单独的处理器内核, 每个内核都可以执行自己的指令,然后通过并行运行,CPU 可以更有效地工作，因此有效周期时间 (`effective CPU cycle time`) 可能会继续下降, 图中底部就是有效周期时间,换言之，是循环时间除以核心数. 2005 年, 出现了第一个两核 cpu,所以你可以运行两个独立的线程或两个独立的程序, 到 2015 年，它发展到了四核服务器级系统，你可以获得八个核心
DRAM、SSD、磁盘和 CPU 之间存在着访问时间的巨大差距,而且在某些情况下，随着时间的推移，它甚至会变得越来越糟，因此这是一个问题: 我们的程序都需要数据,我们的数据存储在内存和磁盘中,所以如果你的计算机变得越来越快,我们的存储设备的访问速度却保持相对不变，甚至变得相对较慢,然后我们就遇到了一个问题，就是我们的计算机性能实际上不会增加,因为我们会受到访问数据所需时间的限制
事实证明，**弥合 CPU 和内存之间差距的关键,是这个非常根本的程序的基本属性 -- 程序的局部性 (`locality`)**
## 程序的局部性
>**Principle of Locality**: Programs tend to use data and instructions with addresses near or equal to those they have used recently
如果程序访问是一个数据项，那么它等一会儿访问该数据项或附近的数据项的可能性非常高, 这就是程序的局部性
![[Pasted image 20250116212608.png]]
通常，局部性有两种不同的形式
- **时间局部性(Temporal locality):** 是最近引用的存储器位置可能在不久的将来再次被引用的属性,例如，你读取了一个变量,你有可能再次阅读该变量
- **空间局部性(Spatial locality):** 是指引用临近存储器位置的倾向,如果我们访问了一个存储器位置。那么有很高的可能性我们在将来会访问一个临近位置
```C
sum=0; 
for (i=0；i<n;i++)
	sum += a[i] ;
return sum;
```
时间局部性: `sum` 一直被访问
空间局部性: 数组 `a`
for循环中的指令一直被执行体现了两种

现在，现在我想对你们说的就是这整个课程的主要观点之一,作为一个专业的程序员,这是一项必不可少的技能：你观看代码，就可以获得对其局部性的定性认识,因为我们会看到，好的程序局部性带来良好的性能
```C
int sum_array_rows(int a[M][N]) {
	int i,j, sum = 0; 
	for (i = 0; i< M; i++) 
		for(j=O;j<N;j++) 
			sum += a[i][j]; 
	return sum;
}
```
上述代码,如果你以使其具有较差的局部性的方式编写此代码，则它将以慢一个数量级的速度运行
!!! 仔细想一想, 二维数组在内存中的存储方式, 是一行一行存储的, 而上述代码是 M 行, 每一行是 N 个元素, N 个 N 个读取, 具有良好的空间局部性 
## Memory Hierarchy
![[Pasted image 20250116214823.png]]
这就是存储器层次结构的概念,将内存系统分层设计、而不是单一的平层, 越往下, 空间更大, 速度更慢
在这个层次结构的顶部,你拥有存储容量较小、访问速度更快，但也更昂贵的存储设备--寄存器, 每个 cpu 周期都可以被访问
这个结构的原理都是基于缓存 cache 的概念
## Cache
![[Pasted image 20250117115517.png]]
以最高层的速度允许, 同时拥有最底层的数据容量
若 cpu 需要的块正好在 cache 中, 就是缓存命中 cache-hit: ![[Pasted image 20250117115958.png]]
与之相反的是 cache-miss: ![[Pasted image 20250117120130.png]]
### Cache misses
- **冷不命中:** cache 中没有任何数据, 最初 cache 是空的,当我们要读取数据时就要从下一级获取块，将它们放入缓存中, 缓存将慢慢填满, 这个过程称为缓存的暖身(warming up cache). `cold miss` 是无法避免的
- **容量不命中 (capacity miss):** 容量不命中的原因是高速缓存的大小是有限的、你不能（容纳超过缓存大小的工作集）,在上面看到的例子中，我们的高速缓存只有四个块的大小.如果我们的程序的局部性需要用到包含8个块的数据,那么容量仅有4个块的高速缓存当然无法放下整个8个块的数组, `capacity miss` 需要更大的缓存解决
	- 一般来说，在程序运行的任何时候,我们将这些不断被程序访问的块称之为工作集（`working set`）,工作集是会改变的，当你的程序从一个循环执行到另一个循环,从一个函数到另一个函数时.在程序执行中的某个时间点,有一个工作集的概念，它就是你需要存储在缓存中的块,所以当你的工作集大小超过你的缓存大小时,就会发生容量不命中
- 冲突未命中 (conflict miss):还有另一种奇怪的缓存不命中，称为冲突未命中,这与缓存的实现方式有关.
	- 这里的概念是、大多数缓存、特别是硬件缓存、因为它们必须设计地较为简单,限制了块可以被放在缓存中的一小组位置, 例如最简单的模型之一就是,块号为i的第i块只能放在（i mod 缓存大小）处 (看看上图中的例子! 正好就是这样的). 假设缓存中可以放四个块, 那么第 1,5, 9 块都会放在 cache 中的第 1 块. 
	- 因此即使有足够大的 cache, 由于访问模式(access pattern)和映射算法
![[Pasted image 20250117120300.png]]
### Examples of Caching in the Mem. Hierarchy
![[Pasted image 20250117122313.png]]
是谁管理缓存？必须要有东西管理缓存.当有请求从层次结构中的较低层读取内容时,必须有一个过程决定如何处理这个清求,如何将其放入的缓存中的某一位置,我们称之为缓存管理
- 在寄存器中, 由编译器管理缓存, 当你编译C语言代码时,编译器会确定由哪个寄存器来存储来自内存的数据项.
- TLB (翻译后备缓冲, Translation Lookaside Buffer) 是一个在虚拟内存中使用的缓存
- $L_1,L_2$ 是硬件寄存器,当CPU要从L1缓存中读取一个内容时，由硬件来管理, 如果出现了未命中, 就会从 $L_2$ 缓存中加载一个块, $L_1$ 缓存中的硬件决定在哪里存放这个块
- 磁盘包含由操作系统维护的缓冲区缓存 (Buffer cache), 在这种情况下, 缓存是文件的一部分, 它们被缓存在主存中, 由 OS 来控制,因此、操作系统会保留一部分内存来存储你已加载的文件.因此，如果你读取文件，操作系统将利用局部性 (locality),然后开始从该文件中读取字节，它实际上将从主存中的文件缓存被读取, 而不是去磁盘上读取
- 网络也维护着一份本地地盘的缓存，例如网络文件系统（Network File System)和安德鲁文件系统(Andrew File System）
- 浏览器有缓存机制, 从服务器获取文件时,浏览器将会把这些文件本地存储在磁盘上、以便再次引用这些网页

这里的理念就是,缓存机制存在于存储器层次结构中的任何位置,而且它们都基于相同的原则，它们只是以不同的方式来实现